{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7BDRrFKLZ7nBIGQkqvBH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prathamr1/Pattern-Recognition/blob/main/bayesian_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚪Use Bayesian Decision theory of statistical pattern recognition to classify the object\n",
        "\n",
        "-Pattern Recognition Laboratory : Group A - Experiment 1\n"
      ],
      "metadata": {
        "id": "jet786nQaPS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bayesian decision theory** refers to *the statistical approach based on tradeoff quantificationamong various classification decisions based on the concept of Probability (Bayes Theorem)and the costs associated with the decision.It is basically a classification technique that involves the use of the Bayes Theorem which isused to find the conditional probabilities*.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In Statistical Pattern Recognition, to will focus on the statistical properties of patterns thatare generally expressed in probability densities (pdf’s and pmf’s), and this will commandmost of the attention in this article and try to develop the fundamentals of the Bayesian\n",
        "decision theory.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "A random variable is a function that maps a possible set of outcomes to some values likewhile tossing a coin and getting head H as 1 and Tail T as 0 where 0 and 1 are randomvariables.Bayes TheoremThe conditional probability of A given B, represented by :\n",
        "\n",
        "(A | B) is the chance ofoccurrence of A given that B has occurred.\n",
        "\n",
        "P(A | B) = P(A,B)/P(B) or\n",
        "\n",
        "By Using the Chain rule, this can also be written as:\n",
        "\n",
        "P(A,B) = P(A|B)P(B)=P(B|A)P(A)P(A | B) = P(B|A)P(A)/P(B)    ——-  (1)\n",
        "\n",
        "Where, P(B) = P(B,A) + P(B,A’) = P(B|A)P(A) + P(B|A’)P(A’)\n",
        "\n",
        "Here, equation (1) is known as the Bayes Theorem of probability\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "k-jLSHhQgcxw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fadba178"
      },
      "source": [
        "## Process / Algorithm\n",
        "1.  **Define Classes and Prior Probabilities:**\n",
        "    *   Identify the possible classes or categories the object can belong to (e.g., \"cat\", \"dog\", \"car\").\n",
        "    *   Determine the prior probability of each class, which is the probability of a class occurring before observing any data about the object. This is often estimated from the overall frequency of each class in the dataset. (P(Class))\n",
        "\n",
        "2.  **Identify Relevant Features:**\n",
        "    *   Determine the features or attributes that describe the object and are relevant for classification (e.g., color, shape, size, texture).\n",
        "\n",
        "3.  **Calculate Likelihoods:**\n",
        "    *   For each class, calculate the likelihood of observing the specific features of the object. This is the conditional probability of the features given the class. (P(Features | Class))\n",
        "\n",
        "4.  **Calculate Marginal Probability of Features:**\n",
        "    *   Calculate the overall probability of observing the specific features of the object, regardless of the class. This is the sum of the likelihood of the features for each class multiplied by its prior probability. (P(Features))\n",
        "    *   P(Features) = Σ \\[ P(Features | Class_i) * P(Class_i) ] for all classes i.\n",
        "\n",
        "5.  **Calculate Posterior Probabilities:**\n",
        "    *   Apply Bayes' Theorem to calculate the posterior probability of each class given the observed features. This is the probability that the object belongs to a specific class given its features. (P(Class | Features))\n",
        "    *   P(Class | Features) = \\[ P(Features | Class) * P(Class) ] / P(Features)\n",
        "\n",
        "6.  **Make a Decision:**\n",
        "    *   Classify the object into the class with the highest posterior probability. This is the class that is most likely given the observed features according to the Bayesian framework.\n",
        "\n",
        "In essence, the Bayesian classifier uses the observed features and the prior knowledge about the classes to determine the most probable class for an object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a83f19ae",
        "outputId": "91299b04-c866-4151-e9b0-a3fe4e33ce0d"
      },
      "source": [
        "try:\n",
        "    P_class_A = float(input(\"Enter Prior Probability of Class A: \"))\n",
        "    P_class_B = float(input(\"Enter Prior Probability of Class B: \"))\n",
        "    P_x_given_class_A = float(input(\"Enter Likelihood of x given Class A: \"))\n",
        "    P_x_given_class_B = float(input(\"Enter Likelihood of x given Class B: \"))\n",
        "\n",
        "    # Ensure probabilities are valid (between 0 and 1)\n",
        "    if not (0 <= P_class_A <= 1 and 0 <= P_class_B <= 1 and\n",
        "            0 <= P_x_given_class_A <= 1 and 0 <= P_x_given_class_B <= 1):\n",
        "        print(\"Error: Probabilities must be between 0 and 1.\")\n",
        "    elif abs(P_class_A + P_class_B - 1.0) > 1e-9: # Check if prior probabilities sum to 1\n",
        "         print(\"Error: Prior probabilities should sum to 1.\")\n",
        "    else:\n",
        "        # Calculate the marginal probability of observing data 'x'\n",
        "        # P(x) = P(x | class A) * P(class A) + P(x | class B) * P(class B)\n",
        "        P_x = (P_x_given_class_A * P_class_A) + (P_x_given_class_B * P_class_B)\n",
        "\n",
        "        # Calculate the posterior probability of each class given data 'x'\n",
        "        # Using Bayes' Theorem: P(class | data) = (P(data | class) * P(class)) / P(data)\n",
        "\n",
        "        # Posterior probability of class A given x\n",
        "        P_class_A_given_x = (P_x_given_class_A * P_class_A) / P_x\n",
        "\n",
        "        # Posterior probability of class B given x\n",
        "        P_class_B_given_x = (P_x_given_class_B * P_class_B) / P_x\n",
        "\n",
        "        print(f\"\\nPrior Probability of Class A: {P_class_A}\")\n",
        "        print(f\"Prior Probability of Class B: {P_class_B}\")\n",
        "        print(f\"Likelihood of x given Class A: {P_x_given_class_A}\")\n",
        "        print(f\"Likelihood of x given Class B: {P_x_given_class_B}\")\n",
        "        print(f\"Marginal Probability of x: {P_x}\")\n",
        "        print(f\"Posterior Probability of Class A given x: {P_class_A_given_x}\")\n",
        "        print(f\"Posterior Probability of Class B given x: {P_class_B_given_x}\")\n",
        "\n",
        "        # Decision Rule: Classify to the class with the higher posterior probability\n",
        "        if P_class_A_given_x > P_class_B_given_x:\n",
        "            print(\"\\nDecision: Classify as Class A\")\n",
        "        else:\n",
        "            print(\"\\nDecision: Classify as Class B\")\n",
        "\n",
        "except ValueError:\n",
        "    print(\"Error: Please enter valid numerical values for probabilities.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Prior Probability of Class A: 0.5\n",
            "Enter Prior Probability of Class B: 0.5\n",
            "Enter Likelihood of x given Class A: 0.1\n",
            "Enter Likelihood of x given Class B: 0.4\n",
            "\n",
            "Prior Probability of Class A: 0.5\n",
            "Prior Probability of Class B: 0.5\n",
            "Likelihood of x given Class A: 0.1\n",
            "Likelihood of x given Class B: 0.4\n",
            "Marginal Probability of x: 0.25\n",
            "Posterior Probability of Class A given x: 0.2\n",
            "Posterior Probability of Class B given x: 0.8\n",
            "\n",
            "Decision: Classify as Class B\n"
          ]
        }
      ]
    }
  ]
}